>- **ğŸ¨ æœ¬æ–‡ä¸º[ğŸ”—365å¤©æ·±åº¦å­¦ä¹ è®­ç»ƒè¥](https://mp.weixin.qq.com/s/xLjALoOD8HPZcH563En8bQ) ä¸­çš„å­¦ä¹ è®°å½•åšå®¢**
>- **ğŸ¦ å‚è€ƒæ–‡ç« ï¼š[Pytorchå®æˆ˜ | ç¬¬P3å‘¨ï¼šå½©è‰²å›¾ç‰‡è¯†åˆ«ï¼šå¤©æ°”è¯†åˆ«](https://www.heywhale.com/mw/project/633567aadfae0249670d0990)**
>- **ğŸ– åŸä½œè€…ï¼š[KåŒå­¦å•Š|æ¥è¾…å¯¼ã€é¡¹ç›®å®šåˆ¶](https://mtyjkh.blog.csdn.net/)**
>
* å…³äºå¯è§†åŒ–æ¨¡å—ï¼Œæ³¨æ„è¿™é‡Œ**transpose**çš„ç”¨æ³•
```python
# æŒ‡å®šå›¾ç‰‡å¤§å°ï¼Œå›¾åƒå¤§å°ä¸º20å®½ã€5é«˜çš„ç»˜å›¾(å•ä½ä¸ºè‹±å¯¸inch)
plt.figure(figsize=(20, 5)) 
for i, imgs in enumerate(imgs[:20]):
    # ç»´åº¦ç¼©å‡
    npimg = imgs.numpy().transpose((1, 2, 0))
    # å°†æ•´ä¸ªfigureåˆ†æˆ2è¡Œ10åˆ—ï¼Œç»˜åˆ¶ç¬¬i+1ä¸ªå­å›¾ã€‚
    plt.subplot(2, 10, i+1)
    plt.imshow(npimg, cmap=plt.cm.binary)
    plt.axis('off')
```
* å…³äºtrainå‡½æ•°å’Œtestå‡½æ•°çš„éƒ¨åˆ†,éœ€è¦æ³¨æ„with torch.no_grad()åéƒ¨åˆ†çš„å†™æ³•
```python
def test (dataloader, model, loss_fn):
    size        = len(dataloader.dataset)  # æµ‹è¯•é›†çš„å¤§å°ï¼Œä¸€å…±10000å¼ å›¾ç‰‡
    num_batches = len(dataloader)          # æ‰¹æ¬¡æ•°ç›®ï¼Œ313ï¼ˆ10000/32=312.5ï¼Œå‘ä¸Šå–æ•´ï¼‰
    test_loss, test_acc = 0, 0
    
    # å½“ä¸è¿›è¡Œè®­ç»ƒæ—¶ï¼Œåœæ­¢æ¢¯åº¦æ›´æ–°ï¼ŒèŠ‚çœè®¡ç®—å†…å­˜æ¶ˆè€—
    with torch.no_grad():
        for imgs, target in dataloader:
            imgs, target = imgs.to(device), target.to(device)
            
            # è®¡ç®—loss
            target_pred = model(imgs)
            loss        = loss_fn(target_pred, target)
            
            test_loss += loss.item()
            test_acc  += (target_pred.argmax(1) == target).type(torch.float).sum().item()

    test_acc  /= size
    test_loss /= num_batches

    return test_acc, test_loss
```

*é—®é¢˜ï¼šimgs.numpy().transpose((1, 2, 0))çš„å…·ä½“ç”¨æ³•ï¼Ÿ
