{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "670793e2-a5f9-42c6-9d33-481958f15133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow import keras\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "785e36e8-f057-422e-a17f-4352d296f574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 565 files belonging to 4 classes.\n",
      "Using 452 files for training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-24 12:48:03.395695: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-24 12:48:04.786069: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10249 MB memory:  -> device: 0, name: NVIDIA RTX A2000 12GB, pci bus id: 0000:04:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 565 files belonging to 4 classes.\n",
      "Using 113 files for validation.\n"
     ]
    }
   ],
   "source": [
    "data_dir = r'./data/bird_photos'\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.2,  #分割数据集\n",
    "    subset=\"training\",          #数据集类型\n",
    "    seed=123,\n",
    "    image_size=(224, 224),\n",
    "    batch_size=32)\n",
    "\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.2,  #分割数据集\n",
    "    subset=\"validation\",          #数据集类型\n",
    "    seed=123,\n",
    "    image_size=(224, 224),\n",
    "    batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9f1369d-ea67-4120-8be7-1106a5f39d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BottleNeck(keras.Model):\n",
    "    def __init__(self, growth_rate, bn_size = 4, dropout = 0.3):\n",
    "        super().__init__()\n",
    "        self.bn1 = layers.BatchNormalization()\n",
    "        self.relu = layers.Activation(\"relu\"),\n",
    "        self.conv1 = layers.Conv2D(filters=bn_size * growth_rate, kernel_size=(1, 1), \n",
    "                                   strides=1, padding='same')\n",
    "        self.bn2 = layers.BatchNormalization()\n",
    "        self.conv2 = layers.Conv2D(filters=growth_rate, kernel_size=(3, 3), \n",
    "                                   strides=1, padding='same')\n",
    "        self.dropout = layers.Dropout(rate=dropout)\n",
    "\n",
    "        self.listLayers = [\n",
    "            self.bn1,\n",
    "            self.relu,\n",
    "            self.conv1,\n",
    "            self.bn2,\n",
    "            self.relu,\n",
    "            self.conv2,\n",
    "            self.dropout\n",
    "            ]\n",
    "        \n",
    "    def call(self, x):\n",
    "        tem = x\n",
    "        for layer in self.listLayers.layers:\n",
    "            x = layer(x)\n",
    "        return layers.concatenate([tem, x], axis=-1)\n",
    "\n",
    "\n",
    "\n",
    "class Transition(tf.keras.Model):\n",
    "    def __init__(self, growth_rate):\n",
    "        super().__init__()\n",
    "        self.bn1 = layers.BatchNormalization()\n",
    "        self.relu = layers.Activation('relu')\n",
    "        self.conv1 = layers.Conv2D(filters = growth_rate, kernel_size=(1, 1),\n",
    "                                   strides = 1, activation = 'relu', padding='same')\n",
    "        self.pooling = layers.AveragePooling2D(pool_size=(2,2), strides = 2,padding='same')\n",
    "\n",
    "        self.listLayers = [\n",
    "            self.bn1,\n",
    "            self.relu,\n",
    "            self.conv1,\n",
    "            self.pooling\n",
    "        ]\n",
    "    def call(self,x):\n",
    "        for layer in self.listLayers.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "class DenseBlock(tf.keras.Model):\n",
    "    def __init__(self, num_layer, growth_rate, bn_size = 4, dropout = 0.3, efficient=False):\n",
    "        super().__init__()\n",
    "        self.efficient = efficient\n",
    "        self.listLayers = []\n",
    "        if self.efficient:\n",
    "            _x = tf.recompute_grad(BottleNeck(growth_rate, bn_size = bn_size, dropout = dropout))\n",
    "        else:_x =BottleNeck(growth_rate, bn_size = bn_size, dropout = dropout)\n",
    "        for _ in range(num_layer):\n",
    "            self.listLayers.append(BottleNeck(growth_rate, bn_size = bn_size, dropout = dropout))\n",
    "    \n",
    "    def call(self, x):\n",
    "        for layer in self.listLayers.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class DenseNet(tf.keras.Model):\n",
    "    def __init__(self, num_init_feature, growth_rate, block_config, num_classes, \n",
    "                 bn_size=4, dropout=0.3, compression_rate=0.5, efficient=False):\n",
    "        super().__init__()\n",
    "        self.num_channels = num_init_feature\n",
    "        self.conv = layers.Conv2D(filters = num_init_feature, kernel_size=7,\n",
    "                                strides = 2, padding='same')\n",
    "        self.bn = layers.BatchNormalization()\n",
    "        self.relu = layers.Activation('relu')\n",
    "        self.max_pool = layers.MaxPool2D(pool_size=3, strides=2, padding='same')\n",
    "\n",
    "        self.dense_block_layers = []\n",
    "        for i in block_config[:-1]:\n",
    "            self.dense_block_layers.append( DenseBlock(num_layer =i, growth_rate = growth_rate,\n",
    "                                                 bn_size = bn_size, dropout = dropout, efficient=efficient))\n",
    "            self.num_channels = compression_rate * (self.num_channels + growth_rate * i)\n",
    "            self.dense_block_layers.append( Transition(self.num_channels))\n",
    "            \n",
    "        self.dense_block_layers.append( DenseBlock(num_layer =block_config[-1], growth_rate = growth_rate,\n",
    "                                             bn_size = bn_size, dropout = dropout, efficient=efficient))\n",
    "        \n",
    "        self.avgpool = layers.GlobalAveragePooling2D()\n",
    "        self.fc = tf.keras.layers.Dense(units=num_classes, activation=tf.keras.activations.softmax)\n",
    "            \n",
    "    def call(self,x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.max_pool(x)\n",
    "        \n",
    "        for layer in self.dense_block_layers.layers:\n",
    "            x = layer(x)\n",
    "\n",
    "        \n",
    "        x = self.avgpool(x)\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7357678-6ecf-456d-9102-e17cc343787c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-24 12:49:30.781500: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d output shape:\t (1, 112, 112, 64)\n",
      "batch_normalization output shape:\t (1, 112, 112, 64)\n",
      "activation output shape:\t (1, 112, 112, 64)\n",
      "max_pooling2d output shape:\t (1, 56, 56, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-24 12:49:34.190024: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense_block output shape:\t (1, 56, 56, 256)\n",
      "transition output shape:\t (1, 28, 28, 128)\n",
      "dense_block_1 output shape:\t (1, 28, 28, 512)\n",
      "transition_1 output shape:\t (1, 14, 14, 256)\n",
      "dense_block_2 output shape:\t (1, 14, 14, 1024)\n",
      "transition_2 output shape:\t (1, 7, 7, 512)\n",
      "dense_block_3 output shape:\t (1, 7, 7, 1024)\n",
      "global_average_pooling2d output shape:\t (1, 1024)\n",
      "dense output shape:\t (1, 4)\n"
     ]
    }
   ],
   "source": [
    "model = DenseNet(num_init_feature=64,\n",
    "                 growth_rate=32,\n",
    "                 block_config=[6,12,24,16],\n",
    "                 compression_rate=0.5,\n",
    "                 num_classes = 4,\n",
    "                 dropout=0.0,\n",
    "                 efficient=True)\n",
    "\n",
    "x = tf.random.normal((1,224,224,3))\n",
    "for layer in model.layers:\n",
    "    x = layer(x)\n",
    "    print(layer.name, 'output shape:\\t', x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d31b8768-0c65-4e4b-ab9d-07fd69e0980a",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ceb744f-eb8a-437d-88b5-d1b9d00b6411",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate=0.002,decay=0.01)\n",
    "\n",
    "model.compile(optimizer=opt,\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "056a83e1-1e61-4c56-9886-1ff751aed4c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/myconda/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 29s 753ms/step - loss: 2.5196 - accuracy: 0.4801 - val_loss: 96574.7109 - val_accuracy: 0.2301\n",
      "Epoch 2/40\n",
      "15/15 [==============================] - 5s 327ms/step - loss: 1.2141 - accuracy: 0.6217 - val_loss: 6833.5015 - val_accuracy: 0.3186\n",
      "Epoch 3/40\n",
      "15/15 [==============================] - 5s 314ms/step - loss: 0.6587 - accuracy: 0.7367 - val_loss: 672.4532 - val_accuracy: 0.3186\n",
      "Epoch 4/40\n",
      "15/15 [==============================] - 5s 314ms/step - loss: 0.5117 - accuracy: 0.8252 - val_loss: 76.6003 - val_accuracy: 0.3186\n",
      "Epoch 5/40\n",
      "15/15 [==============================] - 5s 316ms/step - loss: 0.5910 - accuracy: 0.8009 - val_loss: 31.9198 - val_accuracy: 0.3186\n",
      "Epoch 6/40\n",
      "15/15 [==============================] - 5s 316ms/step - loss: 0.4022 - accuracy: 0.8650 - val_loss: 7.1209 - val_accuracy: 0.3097\n",
      "Epoch 7/40\n",
      "15/15 [==============================] - 5s 315ms/step - loss: 0.2295 - accuracy: 0.9181 - val_loss: 2.9968 - val_accuracy: 0.3628\n",
      "Epoch 8/40\n",
      "15/15 [==============================] - 5s 314ms/step - loss: 0.1383 - accuracy: 0.9425 - val_loss: 2.2953 - val_accuracy: 0.3540\n",
      "Epoch 9/40\n",
      "15/15 [==============================] - 5s 313ms/step - loss: 0.1262 - accuracy: 0.9690 - val_loss: 2.3072 - val_accuracy: 0.2920\n",
      "Epoch 10/40\n",
      "15/15 [==============================] - 5s 313ms/step - loss: 0.0862 - accuracy: 0.9735 - val_loss: 2.7825 - val_accuracy: 0.3363\n",
      "Epoch 11/40\n",
      "15/15 [==============================] - 5s 314ms/step - loss: 0.0637 - accuracy: 0.9779 - val_loss: 1.9153 - val_accuracy: 0.3805\n",
      "Epoch 12/40\n",
      "15/15 [==============================] - 5s 313ms/step - loss: 0.0488 - accuracy: 0.9889 - val_loss: 2.4824 - val_accuracy: 0.3628\n",
      "Epoch 13/40\n",
      "15/15 [==============================] - 5s 312ms/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 2.2868 - val_accuracy: 0.4425\n",
      "Epoch 14/40\n",
      "15/15 [==============================] - 5s 316ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 2.4083 - val_accuracy: 0.4602\n",
      "Epoch 15/40\n",
      "15/15 [==============================] - 5s 313ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 2.3786 - val_accuracy: 0.4867\n",
      "Epoch 16/40\n",
      "15/15 [==============================] - 5s 313ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.2647 - val_accuracy: 0.5044\n",
      "Epoch 17/40\n",
      "15/15 [==============================] - 5s 315ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.1550 - val_accuracy: 0.5044\n",
      "Epoch 18/40\n",
      "15/15 [==============================] - 5s 318ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.0388 - val_accuracy: 0.5221\n",
      "Epoch 19/40\n",
      "15/15 [==============================] - 5s 318ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.9177 - val_accuracy: 0.5487\n",
      "Epoch 20/40\n",
      "15/15 [==============================] - 5s 315ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.7982 - val_accuracy: 0.5575\n",
      "Epoch 21/40\n",
      "15/15 [==============================] - 5s 315ms/step - loss: 9.5616e-04 - accuracy: 1.0000 - val_loss: 1.6740 - val_accuracy: 0.5929\n",
      "Epoch 22/40\n",
      "15/15 [==============================] - 5s 313ms/step - loss: 8.7074e-04 - accuracy: 1.0000 - val_loss: 1.5437 - val_accuracy: 0.6283\n",
      "Epoch 23/40\n",
      "15/15 [==============================] - 5s 316ms/step - loss: 7.9379e-04 - accuracy: 1.0000 - val_loss: 1.4127 - val_accuracy: 0.6549\n",
      "Epoch 24/40\n",
      "15/15 [==============================] - 5s 317ms/step - loss: 7.3498e-04 - accuracy: 1.0000 - val_loss: 1.2893 - val_accuracy: 0.6726\n",
      "Epoch 25/40\n",
      "15/15 [==============================] - 5s 318ms/step - loss: 6.8312e-04 - accuracy: 1.0000 - val_loss: 1.1679 - val_accuracy: 0.6903\n",
      "Epoch 26/40\n",
      "15/15 [==============================] - 5s 316ms/step - loss: 6.3602e-04 - accuracy: 1.0000 - val_loss: 1.0627 - val_accuracy: 0.7080\n",
      "Epoch 27/40\n",
      "15/15 [==============================] - 5s 318ms/step - loss: 5.9658e-04 - accuracy: 1.0000 - val_loss: 0.9683 - val_accuracy: 0.7611\n",
      "Epoch 28/40\n",
      "15/15 [==============================] - 5s 316ms/step - loss: 5.6181e-04 - accuracy: 1.0000 - val_loss: 0.8840 - val_accuracy: 0.7788\n",
      "Epoch 29/40\n",
      "15/15 [==============================] - 5s 332ms/step - loss: 5.3110e-04 - accuracy: 1.0000 - val_loss: 0.8143 - val_accuracy: 0.7788\n",
      "Epoch 30/40\n",
      "15/15 [==============================] - 5s 317ms/step - loss: 5.0385e-04 - accuracy: 1.0000 - val_loss: 0.7509 - val_accuracy: 0.7965\n",
      "Epoch 31/40\n",
      "15/15 [==============================] - 5s 330ms/step - loss: 4.7810e-04 - accuracy: 1.0000 - val_loss: 0.6991 - val_accuracy: 0.8053\n",
      "Epoch 32/40\n",
      "15/15 [==============================] - 5s 330ms/step - loss: 4.5629e-04 - accuracy: 1.0000 - val_loss: 0.6498 - val_accuracy: 0.8407\n",
      "Epoch 33/40\n",
      "15/15 [==============================] - 5s 317ms/step - loss: 4.3549e-04 - accuracy: 1.0000 - val_loss: 0.6129 - val_accuracy: 0.8407\n",
      "Epoch 34/40\n",
      "15/15 [==============================] - 5s 317ms/step - loss: 4.1516e-04 - accuracy: 1.0000 - val_loss: 0.5819 - val_accuracy: 0.8407\n",
      "Epoch 35/40\n",
      "15/15 [==============================] - 5s 317ms/step - loss: 3.9902e-04 - accuracy: 1.0000 - val_loss: 0.5571 - val_accuracy: 0.8761\n",
      "Epoch 36/40\n",
      "15/15 [==============================] - 5s 316ms/step - loss: 3.8288e-04 - accuracy: 1.0000 - val_loss: 0.5327 - val_accuracy: 0.8761\n",
      "Epoch 37/40\n",
      "15/15 [==============================] - 5s 315ms/step - loss: 3.6821e-04 - accuracy: 1.0000 - val_loss: 0.5137 - val_accuracy: 0.8761\n",
      "Epoch 38/40\n",
      "15/15 [==============================] - 5s 317ms/step - loss: 3.5412e-04 - accuracy: 1.0000 - val_loss: 0.4994 - val_accuracy: 0.8761\n",
      "Epoch 39/40\n",
      "15/15 [==============================] - 5s 316ms/step - loss: 3.4210e-04 - accuracy: 1.0000 - val_loss: 0.4837 - val_accuracy: 0.8761\n",
      "Epoch 40/40\n",
      "15/15 [==============================] - 5s 316ms/step - loss: 3.2946e-04 - accuracy: 1.0000 - val_loss: 0.4716 - val_accuracy: 0.8761\n"
     ]
    }
   ],
   "source": [
    "epochs = 40\n",
    "history = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6d57a8-cfc5-447d-8506-8e5a2106ee27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myconda",
   "language": "python",
   "name": "myconda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
