{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6ead3e8-a118-485e-892f-5285e93c77bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code by Tae Hwan Jung(Jeff Jung) @graykode, modify by wmathor\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# S: Symbol that shows starting of decoding input\n",
    "# E: Symbol that shows starting of decoding output\n",
    "# ?: Symbol that will fill in blank sequence if current batch data size is short than n_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d093464-34af-44d2-9128-a47b0df4a6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "letter = [c for c in 'SE?abcdefghijklmnopqrstuvwxyz']\n",
    "letter2idx = {n: i for i, n in enumerate(letter)}\n",
    "\n",
    "seq_data = [['man', 'women'], ['black', 'white'], ['king', 'queen'], ['girl', 'boy'], ['up', 'down'], ['high', 'low'],['big','small']]\n",
    "\n",
    "# Seq2Seq Parameter\n",
    "n_step = max([max(len(i), len(j)) for i, j in seq_data]) # max_len(=5)\n",
    "n_hidden = 128\n",
    "n_class = len(letter2idx) # classfication problem\n",
    "batch_size = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7a9cbe9-74b9-49dd-b033-bcf34ec8f401",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'S': 0,\n",
       " 'E': 1,\n",
       " '?': 2,\n",
       " 'a': 3,\n",
       " 'b': 4,\n",
       " 'c': 5,\n",
       " 'd': 6,\n",
       " 'e': 7,\n",
       " 'f': 8,\n",
       " 'g': 9,\n",
       " 'h': 10,\n",
       " 'i': 11,\n",
       " 'j': 12,\n",
       " 'k': 13,\n",
       " 'l': 14,\n",
       " 'm': 15,\n",
       " 'n': 16,\n",
       " 'o': 17,\n",
       " 'p': 18,\n",
       " 'q': 19,\n",
       " 'r': 20,\n",
       " 's': 21,\n",
       " 't': 22,\n",
       " 'u': 23,\n",
       " 'v': 24,\n",
       " 'w': 25,\n",
       " 'x': 26,\n",
       " 'y': 27,\n",
       " 'z': 28}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "letter2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "091618d9-f95a-4de3-b055-1dd9d6f2fd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data(seq_data):\n",
    "    enc_input_all, dec_input_all, dec_output_all = [], [], []\n",
    "\n",
    "    for seq in seq_data:\n",
    "        for i in range(2):\n",
    "            seq[i] = seq[i] + '?' * (n_step - len(seq[i])) # 'man??', 'women'\n",
    "\n",
    "        enc_input = [letter2idx[n] for n in (seq[0]+'E')] # ['m', 'a', 'n', '?', '?', 'E']\n",
    "        dec_input = [letter2idx[n] for n in ('S' + seq[1])] # ['S', 'w', 'o', 'm', 'e', 'n']\n",
    "        dec_output = [letter2idx[n] for n in (seq[1] + 'E')] # ['w', 'o', 'm', 'e', 'n', 'E']\n",
    "\n",
    "        enc_input_all.append(enc_input)\n",
    "        dec_input_all.append(dec_input)\n",
    "        dec_output_all.append(dec_output) # not one-hot\n",
    "\n",
    "    # make tensor\n",
    "    return torch.LongTensor(enc_input_all), torch.LongTensor(dec_input_all), torch.LongTensor(dec_output_all)\n",
    "\n",
    "'''\n",
    "enc_input_all: [6, n_step+1 (because of 'E'), n_class]\n",
    "dec_input_all: [6, n_step+1 (because of 'S'), n_class]\n",
    "dec_output_all: [6, n_step+1 (because of 'E')]\n",
    "'''\n",
    "enc_input_all, dec_input_all, dec_output_all = make_data(seq_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d722d6fd-7d4b-4e16-9e6e-677ded62acf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 6])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_input_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1fedcf6-eef8-4504-8879-f03cfe75ab6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranslateDataSet(Data.Dataset):\n",
    "    def __init__(self, enc_input_all, dec_input_all, dec_output_all):\n",
    "        self.enc_input_all = enc_input_all\n",
    "        self.dec_input_all = dec_input_all\n",
    "        self.dec_output_all = dec_output_all\n",
    "    \n",
    "    def __len__(self): # return dataset size\n",
    "        return len(self.enc_input_all)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.enc_input_all[idx], self.dec_input_all[idx], self.dec_output_all[idx]\n",
    "\n",
    "loader = Data.DataLoader(TranslateDataSet(enc_input_all, dec_input_all, dec_output_all), batch_size, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4bbc97b-7e4b-482f-9c9d-6438e124e4ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 6])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_input_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f43a75b7-cc7e-47ed-9553-b37293d1e1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqEncoder(nn.Module):\n",
    "    def __init__(self,vocab_size,embed_size,num_hiddens):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size,embed_size)\n",
    "        self.rnn = nn.GRU(embed_size,num_hiddens)\n",
    "        \n",
    "    def forward(self,X):\n",
    "        X = self.embedding(X)\n",
    "        X = X.permute(1,0,2)\n",
    "        # output的形状:(num_steps,batch_size,num_hiddens)\n",
    "        # state的形状:(num_layers,batch_size,num_hiddens)\n",
    "        output,state = self.rnn(X)\n",
    "        return output,state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec7e52b2-7dc1-43b7-9fdc-f751905f9b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqDecoder(nn.Module):\n",
    "    def __init__(self,vocab_size,embed_size,num_hiddens):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size,embed_size)\n",
    "        self.rnn = nn.GRU(embed_size+num_hiddens,num_hiddens)\n",
    "        self.dense = nn.Linear(num_hiddens,vocab_size)\n",
    "        \n",
    "    def init_state(self,enc_outputs):\n",
    "        return enc_outputs[1]\n",
    "    \n",
    "    def forward(self,X,state):\n",
    "        X = self.embedding(X).permute(1,0,2)\n",
    "        context = state[-1].repeat(X.shape[0],1,1)\n",
    "        X_and_context = torch.cat((X,context),dim=2)\n",
    "        output,state = self.rnn(X_and_context,state)\n",
    "        output = self.dense(output).permute(1,0,2)\n",
    "        # output的形状:(batch_size,num_steps,vocab_size)\n",
    "        # state的形状:(num_layers,batch_size,num_hiddens)\n",
    "        return output,state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc785a44-bd28-41d5-a5ac-a4c0f0029f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoder(nn.Module):\n",
    "    \"\"\"编码器-解码器架构的基类\"\"\"\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(EncoderDecoder, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "    def forward(self, enc_X, dec_X, *args):\n",
    "        enc_outputs = self.encoder(enc_X, *args) # 这里的outputs输出的是一个元组，1代表encoder的state\n",
    "        dec_state = self.decoder.init_state(enc_outputs, *args)\n",
    "        return self.decoder(dec_X, dec_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a20ff34-1937-4b18-a928-d188f551e11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Seq2SeqEncoder(n_class,5,n_hidden)\n",
    "decoder = Seq2SeqDecoder(n_class,5,n_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77931410-b1c0-4504-9698-af917e25f562",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EncoderDecoder(encoder,decoder).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a13e44e-5ba2-48db-8e76-3d1479bf2b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c039db28-7493-4fea-b177-8757beccfad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xavier_init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "    if type(m) == nn.GRU:\n",
    "        for param in m._flat_weights_names:\n",
    "            if \"weight\" in param:\n",
    "                nn.init.xavier_uniform_(m._parameters[param])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c236a78d-e5ed-44d4-a405-befda645023b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1000 cost = 3.433763\n",
      "Epoch: 2000 cost = 3.353740\n",
      "Epoch: 3000 cost = 3.415884\n",
      "Epoch: 4000 cost = 3.327003\n",
      "Epoch: 5000 cost = 3.415658\n",
      "Epoch: 6000 cost = 3.383410\n",
      "Epoch: 7000 cost = 3.383352\n",
      "Epoch: 8000 cost = 3.343417\n",
      "Epoch: 9000 cost = 3.353258\n",
      "Epoch: 10000 cost = 3.415230\n",
      "Epoch: 11000 cost = 3.347921\n",
      "Epoch: 12000 cost = 3.347865\n",
      "Epoch: 13000 cost = 3.353030\n",
      "Epoch: 14000 cost = 3.326344\n",
      "Epoch: 15000 cost = 3.432687\n",
      "Epoch: 16000 cost = 3.432620\n",
      "Epoch: 17000 cost = 3.414704\n",
      "Epoch: 18000 cost = 3.347489\n",
      "Epoch: 19000 cost = 3.352634\n",
      "Epoch: 20000 cost = 3.414444\n",
      "Epoch: 21000 cost = 3.352488\n",
      "Epoch: 22000 cost = 3.352410\n",
      "Epoch: 23000 cost = 3.343051\n",
      "Epoch: 24000 cost = 3.414085\n",
      "Epoch: 25000 cost = 3.431927\n",
      "Epoch: 26000 cost = 3.347023\n",
      "Epoch: 27000 cost = 3.352031\n",
      "Epoch: 28000 cost = 3.351951\n",
      "Epoch: 29000 cost = 3.413639\n",
      "Epoch: 30000 cost = 3.351785\n",
      "Epoch: 31000 cost = 3.413450\n",
      "Epoch: 32000 cost = 3.351614\n",
      "Epoch: 33000 cost = 3.325371\n",
      "Epoch: 34000 cost = 3.346564\n",
      "Epoch: 35000 cost = 3.413067\n",
      "Epoch: 36000 cost = 3.431046\n",
      "Epoch: 37000 cost = 3.325127\n",
      "Epoch: 38000 cost = 3.325048\n",
      "Epoch: 39000 cost = 3.346256\n",
      "Epoch: 40000 cost = 3.346188\n",
      "Epoch: 41000 cost = 3.382155\n",
      "Epoch: 42000 cost = 3.412474\n",
      "Epoch: 43000 cost = 3.324578\n",
      "Epoch: 44000 cost = 3.342648\n",
      "Epoch: 45000 cost = 3.381949\n",
      "Epoch: 46000 cost = 3.412190\n",
      "Epoch: 47000 cost = 3.381827\n",
      "Epoch: 48000 cost = 3.345659\n",
      "Epoch: 49000 cost = 3.411979\n",
      "Epoch: 50000 cost = 3.430221\n"
     ]
    }
   ],
   "source": [
    "model.apply(xavier_init_weights)\n",
    "model.train()\n",
    "for epoch in range(50000):\n",
    "    for enc_input_batch, dec_input_batch, dec_output_batch in loader:\n",
    "      # make hidden shape [num_layers * num_directions, batch_size, n_hidden]\n",
    "        (enc_input_batch, dec_intput_batch, dec_output_batch) = (enc_input_batch.to(device), dec_input_batch.to(device), dec_output_batch.to(device))\n",
    "      # enc_input_batch : [batch_size, n_step+1, n_class]\n",
    "      # dec_intput_batch : [batch_size, n_step+1, n_class]\n",
    "      # dec_output_batch : [batch_size, n_step+1], not one-hot\n",
    "        pred,_ = model(enc_input_batch, dec_intput_batch)\n",
    "      # pred : [n_step+1, batch_size, n_class]\n",
    "        loss = 0\n",
    "        for i in range(len(dec_output_batch)):\n",
    "          # pred[i] : [n_step+1, n_class]\n",
    "          # dec_output_batch[i] : [n_step+1]\n",
    "            loss += criterion(pred[i], dec_output_batch[i])\n",
    "    if (epoch + 1) % 1000 == 0:\n",
    "        print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.6f}'.format(loss))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a55d3a69-6144-4a34-8ee4-5b1eddf7d06a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "tensor([[0]], device='cuda:0')\n",
      "man -> sqiofj\n",
      "tensor([[0]], device='cuda:0')\n",
      "mans -> uqiuzx\n",
      "tensor([[0]], device='cuda:0')\n",
      "king -> sqioff\n",
      "tensor([[0]], device='cuda:0')\n",
      "black -> uqiiof\n",
      "tensor([[0]], device='cuda:0')\n",
      "up -> sqiofx\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "def translate(word):\n",
    "    #model.eval()\n",
    "    enc_input, dec_input, _ = make_data([[word, '?' * n_step]])\n",
    "    enc_input, dec_input = enc_input.to(device), dec_input.to(device)\n",
    "    enc_outputs = model.encoder(enc_input)\n",
    "    dec_state = model.decoder.init_state(enc_outputs)\n",
    "    dec_input = torch.LongTensor([[0]]).to(device)\n",
    "    print(dec_input)\n",
    "    res = ''\n",
    "    for _ in range(6):\n",
    "        Y,dec_state = model.decoder(dec_input,dec_state)\n",
    "        dec_input = Y.argmax(2)\n",
    "        res+= letter[int(dec_input[0][0])]\n",
    "    return res\n",
    "\n",
    "        \n",
    "print('test')\n",
    "print('man ->', translate('man'))\n",
    "print('mans ->', translate('mans'))\n",
    "print('king ->', translate('king'))\n",
    "print('black ->', translate('black'))\n",
    "print('up ->', translate('up'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f88e4ff-d466-4078-9ef4-e825cdf97a77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90995977-9a87-4b82-8784-c08e23461711",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myconda",
   "language": "python",
   "name": "myconda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
