这一次复现的主要感觉是要注意在pytorch中，

其实已经集成了分组卷积的内容，即在nn.Conv2d中，已经有groups参数，这部分和tensorflow的定义有较大的不同

针对于filter乘以2的那个问题，这个地方主要还是自己当时没有思考准确，在代码
```python
class Resnet50Xt(nn.Module):
    def __init__(self,num_classes):
        super().__init__()
        self.conv1 = nn.Conv2d(3,64,kernel_size=(7,7),stride=2,padding=(3,3))
        self.bn1 = nn.BatchNorm2d(64)
        self.maxpool = nn.MaxPool2d(3,2,1)
        self.stack = nn.Sequential(
        stack(64,128,2,1),
        stack(128,256,3,2),
        stack(256,512,5,2),
        stack(512,1024,2,2))
        self.fc = nn.Linear(65536,4)
    def forward(self,x):
        x = self.conv1(x)
        x = self.maxpool(x)
        x = self.stack(x)
        x = F.avg_pool2d(x, 7)
        x = x.view(x.size(0), -1)
        x = self.fc(x)
        x = F.softmax(x,dim=1)
        return x
```
这一部分，没有搞清楚stack内部具体是怎么样去进行运算的，导致了
```python
class stack(nn.Module):
    def __init__(self,in_channels,out_channels,blocks,strides,groups=32):
        super(stack,self).__init__()
        self.block1 = block(in_channels,out_channels,groups = groups) # in_channels=64,out_channels=128
        self.block2 = block(out_channels,out_channels,groups=groups)
        self.blocknum = blocks
    def forward(self,x):
        x = self.block1(x)
        for i in range(self.blocknum):
            x = self.block2(x)
        return x
```
这一步其实算的有一些问题，在K导的代码中，filter看似是输出的通道数，实际上当x真正输出的时候，

输出的应该是2 x filter，也即第一步输入filter是128的时候，实际上x输出的通道数应该是256，这样就不会导致出现通道数不匹配的问题

因为第一步中，在block模块，参数conv_shortcut=True，即x输出通道数经过第一次的self.block1(x)之后，输出通道一直保持2 x filter，因此后面的计算不会有任何问题
